{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Matching Models for Question Retrieval and Next Question Prediction in Conversation\n",
    "## RNN CNN Match\n",
    "### Implementation\n",
    "#### https://arxiv.org/pdf/1707.05409.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обязательная часть:\n",
    "\n",
    "1. Подготовка данных (отчистка и векторизация). Разбиение на train/test\n",
    "1. Реализация модели LSTM-CNN-Match. В качестве функции потерь использовать бинарную кросс-энтропию. (Помните, что у двух башен модели должны быть одинаковые веса)\n",
    "1. Обучение.\n",
    "1. Выводы по метрикам/лоссу. Общие выводы по модели\n",
    "1. Сделать коммит на kaggle.\n",
    "\n",
    "### Необязательная часть:\n",
    "\n",
    "1. Попробовать добавить предобученные word2vec/fasttext эмбеддинги. Сравнить качество моделей.\n",
    "1. Попробовать реализовать Œpairwise ranking-based hinge loss. Сравнить с кросс-энтропией. Где качество получается лучше?\n",
    "1. Сравнить adam и rmsprop оптимайзеры.\n",
    "1. Попробовать LSTM заменить на GRU. Сравнить качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно для задач достаточно Jupyter Notebook, но я посчитал нужным в этой задаче подойти более структурировано, чтобы можно было легко менять нужные мне блоки сети, чтобы код и подход был понятней, быстрее эксперементировать, менять нужные мне части, например составление датасета, генерацию негативных примеров.\n",
    "\n",
    "![alt text](./images/my_arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "**Цель** — перевести файл с данными в массив из индексов.  \n",
    "**Описание** — читаем файлы, чистим данные, создаем словарь, подготавливаем батч. Читает и `test.csv` и `sample_submission.csv`, потому что тестовый файл кривой и его надо преобразовать, то есть для воспроизводимости. Тексты, которые семплируются для отрицательных примеров взяты из всего датасета. Негативные примеры для кросс энтропии не брал из датасета. Неизвестно как поступил Liu Yang в своей статье, возможно негативные примеры он семплирует только из положительно размеченных примеров, отбросив отрицательную часть датасета, на вопросы в линкед ине и фейсбуке не отвечает.\n",
    "## Cleaner\n",
    "**Цель** — очистить текст от ненужной информации, например удаление ненужных символов, замена чисел и тд.  \n",
    "**Описание** — На этом пукте можно сидеть вечно, по разному преобразовывая текст, к тому же очень много кернелов на кейгле по предобработке текста конкретно по этой задаче. Поэтому я не ставил себе цель много времени уделять этому пукту, оставив для этого возможность, если будет достаточно свободного времени.\n",
    "## Layers\n",
    "**Цель** — сделать основные слои.  \n",
    "**Описание** — такой подход нужен для переиспользованиия и контроля этих слоев. Например, в слое CNN в методе forward есть транспонирование, в RNN есть упаковка последовательностей разной длины при заданном `x_lengths`. \n",
    "## Models\n",
    "**Цель** — контроль моделей.  \n",
    "**Описание** — есть возможность изменять обособленно только архитектуру модели.\n",
    "## Templates\n",
    "**Цель** — основные методы для работы с моделью.     \n",
    "**Описание** — если в `Models` задается только архитектура башни, то здесь вся модель и необходимые для нее методы, например `text_embedding` для эмбеддинга батча текстов без расчета градиентов, расчет реколла, лосса и тд.\n",
    "## Wrapper\n",
    "**Цель** — основной класс для работы с моделью и данными.    \n",
    "**Описание** — здесь можно задать то, как будет учиться модель и на каких данных, учить модель, сохранить лучшую, вывести метрики, построить графики, например, лосса, сделать сабмит.\n",
    "### Hard negative\n",
    "1. Берем query батч\n",
    "1. Берем рандомные примеры, количество задается `batch_size * hard_negatives_multiplier`, но не больше `max_hard_negatives`, чтобы влезть в память.\n",
    "1. Векторизуем query батч и рандомные примеры из предыдущего пункта\n",
    "1. Матрично перемножаем (рандомные примеры транспонируются), получаем матрицу размером `(batch_size, batch_size * hard_negatives_multiplier)`\n",
    "1. Из нее с помощью `argmax` достаем наиболее релевантные примеры. Нам не важно насколько похожи примеры, нам важно, чтобы они были максимально похожи среди тех, что мы выбрали\n",
    "1. Если задан параметр `hard_k_next`, то из получившийся матрицы вычитаем матрицу такого же размера, где все нули, кроме `argmax` индексов, где сохраняются значения. Мотивация: не выбирать самый соответствующий пример, а выбирать следующий. Например, чтобы избежать выбор самого элемента при большом размере `batch_size` и `batch_size * hard_negatives_multiplier`\n",
    "1. Отдаем релевантные примеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорты\n",
    "import torch\n",
    "from tools import config, Wrapper, DatasetQuora\n",
    "from modelling.models import RNNCNNMatch\n",
    "from modelling.templates import SimilarityTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем класс датасета\n",
    "dataset = DatasetQuora(train_file=config.TRAIN_FILE,\n",
    "                       test_file=config.TEST_FILE, \n",
    "                       sample_submission_file=config.SAMPLE_SUBMISSION_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем модель\n",
    "rnn_cnn_match = SimilarityTemplate(\n",
    "    query_model=RNNCNNMatch(), \n",
    "    vocab_size=len(dataset.token2index),\n",
    "    loss_type='cross_entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем оптимизатор\n",
    "optimizer = torch.optim.Adam(rnn_cnn_match.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем обертку\n",
    "rcm = Wrapper(dataset=dataset, \n",
    "              model=rnn_cnn_match, \n",
    "              optimizer=optimizer, \n",
    "              model_name=config.MODEL_NAME, \n",
    "              batch_size=32,\n",
    "              generate_negatives_type='random',\n",
    "              validation_batch_size_multiplier=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучение, по дефолту - 5 эпох\n",
    "# rcm.train(verbose=config.VERBOSE, save_best=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Архитектура сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimilarityTemplate(\n",
       "  (query_embedding_layer): Embedding(79279, 300, padding_idx=0)\n",
       "  (candidate_embedding_layer): Embedding(79279, 300, padding_idx=0)\n",
       "  (query_model): RNNCNNMatch(\n",
       "    (fully_connected): Linear(in_features=896, out_features=300, bias=True)\n",
       "    (model): Sequential(\n",
       "      (0): RNN(\n",
       "        (rnn): LSTM(300, 256)\n",
       "      )\n",
       "      (1): CNN(\n",
       "        (convolution_layer): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (2): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(2,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (3): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (4): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(4,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (5): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (candidate_model): RNNCNNMatch(\n",
       "    (fully_connected): Linear(in_features=896, out_features=300, bias=True)\n",
       "    (model): Sequential(\n",
       "      (0): RNN(\n",
       "        (rnn): LSTM(300, 256)\n",
       "      )\n",
       "      (1): CNN(\n",
       "        (convolution_layer): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (2): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(2,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (3): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (4): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(4,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (5): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (similarity_function): CosineSimilarity()\n",
       "  (loss): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_cnn_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Результаты\n",
    "\n",
    "Обучался на http://floydhub.com/  \n",
    "Эмбеддинги: https://www.floydhub.com/gpostelnicu/datasets/fasttext-crawl-300d-2m  \n",
    "Датасет: https://www.floydhub.com/pseudogram/datasets/quora_question_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCE with random negatives\n",
    "### Логи\n",
    "\n",
    "```\n",
    "Epoch: [1/15] | Cross_entropy loss: 0.770 | Validation Loss: 0.456  \n",
    "Mean Recall: 0.76 | Validation Recall: 0.80\n",
    "Epoch: [2/15] | Cross_entropy loss: 0.300 | Validation Loss: 0.365\n",
    "Mean Recall: 0.87 | Validation Recall: 0.85\n",
    "Epoch: [3/15] | Cross_entropy loss: 0.242 | Validation Loss: 0.379\n",
    "Mean Recall: 0.90 | Validation Recall: 0.84\n",
    "Epoch: [4/15] | Cross_entropy loss: 0.205 | Validation Loss: 0.349\n",
    "Mean Recall: 0.92 | Validation Recall: 0.86\n",
    "Epoch: [5/15] | Cross_entropy loss: 0.177 | Validation Loss: 0.367\n",
    "Mean Recall: 0.93 | Validation Recall: 0.86\n",
    "Epoch: [6/15] | Cross_entropy loss: 0.159 | Validation Loss: 0.362\n",
    "Mean Recall: 0.94 | Validation Recall: 0.86\n",
    "Epoch: [7/15] | Cross_entropy loss: 0.148 | Validation Loss: 0.389\n",
    "Mean Recall: 0.95 | Validation Recall: 0.86\n",
    "Epoch: [8/15] | Cross_entropy loss: 0.131 | Validation Loss: 0.334\n",
    "Mean Recall: 0.95 | Validation Recall: 0.87\n",
    "Epoch: [9/15] | Cross_entropy loss: 0.123 | Validation Loss: 0.374\n",
    "Mean Recall: 0.96 | Validation Recall: 0.86\n",
    "Epoch: [10/15] | Cross_entropy loss: 0.116 | Validation Loss: 0.419\n",
    "Mean Recall: 0.96 | Validation Recall: 0.86\n",
    "Epoch: [11/15] | Cross_entropy loss: 0.107 | Validation Loss: 0.388\n",
    "Mean Recall: 0.96 | Validation Recall: 0.87\n",
    "Epoch: [12/15] | Cross_entropy loss: 0.106 | Validation Loss: 0.450\n",
    "Mean Recall: 0.96 | Validation Recall: 0.85\n",
    "Epoch: [13/15] | Cross_entropy loss: 0.099 | Validation Loss: 0.454\n",
    "Mean Recall: 0.97 | Validation Recall: 0.85\n",
    "Epoch: [14/15] | Cross_entropy loss: 0.098 | Validation Loss: 0.401\n",
    "Mean Recall: 0.97 | Validation Recall: 0.86\n",
    "Epoch: [15/15] | Cross_entropy loss: 0.093 | Validation Loss: 0.468\n",
    "Mean Recall: 0.97 | Validation Recall: 0.85\n",
    "```\n",
    "\n",
    "###  График лосса на трейне\n",
    "![alt text](./images/random_ce_tr.png)\n",
    "\n",
    "### Вывод\n",
    "\n",
    "Лосс на трейне стабильно падает, на валидации +- остается таким же как раз-таки из-за того, что примеры рандомные. Такой подход потребует очень много времени на обучение.\n",
    "\n",
    "#### Файл\n",
    "ce_trainable_random.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCE with hard negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TripletMarginLoss with hard negatives and pretrained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучать надо долго и сквозь пальцы смотреть на метрики из-за рандома и что все схлопывается потом в 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Резюме\n",
    "\n",
    "### Обязательная часть:\n",
    "\n",
    "1. ~~Подготовка данных (отчистка и векторизация). Разбиение на train/test~~  \n",
    "1. ~~Реализация модели LSTM-CNN-Match. В качестве функции потерь использовать бинарную кросс-энтропию. (Помните, что у двух башен модели должны быть одинаковые веса)~~  \n",
    "1. ~~Обучение.~~  \n",
    "1. ~~Выводы по метрикам/лоссу. Общие выводы по модели~~  \n",
    "1. ~~Сделать коммит на kaggle.~~  \n",
    "\n",
    "### Необязательная часть:\n",
    "\n",
    "1. ~~Попробовать добавить предобученные word2vec/fasttext эмбеддинги. Сравнить качество моделей.~~  \n",
    "1. ~~Попробовать реализовать Œpairwise ranking-based hinge loss. Сравнить с кросс-энтропией. Где качество получается лучше?~~\n",
    "1. Сравнить adam и rmsprop оптимайзеры.\n",
    "1. Попробовать LSTM заменить на GRU. Сравнить качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

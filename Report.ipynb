{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Matching Models for Question Retrieval and Next Question Prediction in Conversation\n",
    "## RNN CNN Match\n",
    "### Implementation\n",
    "#### https://arxiv.org/pdf/1707.05409.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Подготовка данных (отчистка и векторизация). Разбиение на train/test\n",
    "1. Реализация модели LSTM-CNN-Match. В качестве функции потерь использовать бинарную кросс-энтропию. (Помните, что у двух башен модели должны быть одинаковые веса)\n",
    "1. Обучение.\n",
    "1. Выводы по метрикам/лоссу. Общие выводы по модели\n",
    "1. Сделать коммит на kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebooks хорошее решение, но иногда не самое практичное и порой далеко не самое воспроизводимое. Я хотел сделать небольшую архитектуру проекта для этого задания, чтобы можно было легко менять нужные мне блоки сети, чтобы код и подход был понятней, быстрее эксперементировать, менять нужные мне части, например составление датасета, генерацию негативных примеров.\n",
    "\n",
    "## Архитектура проекта\n",
    "![alt text](./images/my_arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "**Цель** — перевести файл с данными в массив из индексов.  \n",
    "**Описание** — читаем файлы, чистим данные, создаем словарь, подготавливаем батч. Читает и `test.csv` и `sample_submission.csv`, потому что тестовый файл кривой и его надо преобразовать, то есть для воспроизводимости.\n",
    "## Cleaner\n",
    "**Цель** — очистить текст от ненужной информации, например удаление ненужных символов, замена чисел и тд.  \n",
    "**Описание** — На этом пукте можно сидеть вечно, по разному преобразовывая текст, к тому же очень много кернелов на кейгле по предобработке текста конкретно по этой задаче. Поэтому я не ставил себе цель много времени уделять этому пукту, оставив для этого возможность, если будет достаточно свободного времени.\n",
    "## Layers\n",
    "**Цель** — сделать основные слои.  \n",
    "**Описание** — такой подход нужен для переиспользованиия и контроля этих слоев. Например, в слое CNN в методе forward есть транспонирование, в RNN есть упаковка последовательностей разной длины при заданном `x_lengths`. \n",
    "## Models\n",
    "**Цель** — контроль моделей.  \n",
    "**Описание** — есть возможность изменять обособленно только архитектуру модели.\n",
    "## Templates\n",
    "**Цель** — основные методы для работы с моделью.     \n",
    "**Описание** — если в `Models` задается только архитектура башни, то здесь вся модель и необходимые для нее методы, например `text_embedding` для эмбеддинга батча текстов без расчета градиентов, расчет реколла, лосса и тд.\n",
    "## Wrapper\n",
    "**Цель** — основной класс для работы с моделью и данными.    \n",
    "**Описание** — здесь можно задать то, как будет учиться модель и на каких данных, учить модель, сохранить лучшую, вывести метрики, построить графики, например, лосса, сделать сабмит.\n",
    "### Hard negative generation\n",
    "1. Берем query батч\n",
    "1. Берем рандомные примеры, количество задается `batch_size * hard_negatives_multiplier`, но не больше `max_hard_negatives`, чтобы влезть в память.\n",
    "1. Векторизуем query батч и рандомные примеры из предыдущего пункта\n",
    "1. Матрично перемножаем (рандомные примеры транспонируются), получаем матрицу размером `(batch_size, batch_size * hard_negatives_multiplier)`\n",
    "1. Из нее с помощью `argmax` достаем наиболее релевантные примеры. Нам не важно насколько похожи примеры, нам важно, чтобы они были максимально похожи среди тех, что мы выбрали\n",
    "1. Если задан параметр `hard_k_next`, то из получившийся матрицы вычитаем матрицу такого же размера, где все нули, кроме `argmax` индексов, где сохраняются значения. Мотивация: не выбирать самый соответствующий пример, а выбирать следующий. Например, чтобы избежать выбор самого элемента при большом размере `batch_size` и `batch_size * hard_negatives_multiplier`\n",
    "1. Отдаем релевантные примеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорты\n",
    "import torch\n",
    "from tools import config, Wrapper, DatasetQuora\n",
    "from modelling.models import RNNCNNMatch\n",
    "from modelling.templates import SimilarityTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем класс датасета\n",
    "dataset = DatasetQuora(train_file=config.TRAIN_FILE,\n",
    "                       test_file=config.TEST_FILE, \n",
    "                       sample_submission_file=config.SAMPLE_SUBMISSION_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем модель\n",
    "rnn_cnn_match = SimilarityTemplate(\n",
    "    query_model=RNNCNNMatch(), \n",
    "    vocab_size=len(dataset.token2index),\n",
    "    loss_type='cross_entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем оптимизатор\n",
    "optimizer = torch.optim.Adam(rnn_cnn_match.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем обертку\n",
    "rcm = Wrapper(dataset=dataset, \n",
    "              model=rnn_cnn_match, \n",
    "              optimizer=optimizer, \n",
    "              model_name=config.MODEL_NAME, \n",
    "              batch_size=32,\n",
    "              generate_negatives_type='hard', \n",
    "              hard_negatives_multiplier=32, \n",
    "              validation_batch_size_multiplier=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучение, по дефолту - 5 эпох\n",
    "# rcm.train(verbose=config.VERBOSE, save_best=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Архитектура сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimilarityTemplate(\n",
       "  (query_embedding_layer): Embedding(79279, 300, padding_idx=0)\n",
       "  (candidate_embedding_layer): Embedding(79279, 300, padding_idx=0)\n",
       "  (query_model): RNNCNNMatch(\n",
       "    (fully_connected): Linear(in_features=896, out_features=300, bias=True)\n",
       "    (model): Sequential(\n",
       "      (0): RNN(\n",
       "        (rnn): LSTM(300, 256)\n",
       "      )\n",
       "      (1): CNN(\n",
       "        (convolution_layer): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (2): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(2,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (3): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (4): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(4,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (5): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (candidate_model): RNNCNNMatch(\n",
       "    (fully_connected): Linear(in_features=896, out_features=300, bias=True)\n",
       "    (model): Sequential(\n",
       "      (0): RNN(\n",
       "        (rnn): LSTM(300, 256)\n",
       "      )\n",
       "      (1): CNN(\n",
       "        (convolution_layer): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (2): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(2,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (3): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (4): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(4,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (5): CNN(\n",
       "        (convolution_layer): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
       "        (activation_function): GELU()\n",
       "        (pool_layer): MaxPool1d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (similarity_function): CosineSimilarity()\n",
       "  (loss): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_cnn_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN CNN Match with hard negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что зашло"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
